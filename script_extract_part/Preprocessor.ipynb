{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec0bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = \"a's, able, im, uh, about, cod't, cont'd, above, according, accordingly, across, actually, after, afterwards, again, against, ain’t, all, allow, allows, almost, alone, along, already, also, although, always, am, among, amongst, an, and, another, any, anybody, anyhow, anyone, anything, anyway, anyways, anywhere, apart, appear, appreciate, appropriate, are, aren’t, around, as, aside, ask, asking, associated, at, available, away, awfully, be, became, because, become, becomes, becoming, been, before, beforehand, behind, being, believe, below, beside, besides, best, better, between, beyond, both, brief, but, by, c’mon, c’s, came, can, can’t, cannot, cant, cause, causes, certain, certainly, changes, clearly, co, com, come, comes, concerning, consequently, consider, considering, contain, containing, contains, corresponding, could, couldn’t, course, currently, definitely, described, despite, did, didn’t, different, do, does, doesn’t, doing, don’t, done, down, downwards, during, each, edu, eg, eight, either, else, elsewhere, enough, entirely, especially, et, etc, even, ever, every, everybody, everyone, everything, everywhere, ex, exactly, example, except, far, few, fifth, first, five, followed, following, follows, for, former, formerly, forth, four, from, further, furthermore, get, gets, getting, given, gives, go, goes, going, gone, got, gotten, greetings, had, hadn’t, happens, hardly, has, hasn’t, have, haven’t, having, he, he’s, hello, help, hence, her, here, here’s, hereafter, hereby, herein, hereupon, hers, herself, hi, him, himself, his, hither, hopefully, how, howbeit, however, i, i’d, i’ll, i’m, i’ve, ie, if, ignored, immediate, in, inasmuch, inc, indeed, indicate, indicated, indicates, inner, insofar, instead, into, inward, is, isn’t, it, it’d, it’ll, it’s, its, itself, just, keep, keeps, kept, know, knows, known, last, lately, later, latter, latterly, least, less, lest, let, let’s, like, liked, likely, little, look, looking, looks, ltd, mainly, many, may, maybe, me, mean, meanwhile, merely, might, more, moreover, most, mostly, much, must, my, myself, name, namely, nd, near, nearly, necessary, need, needs, neither, never, nevertheless, new, next, nine, no, nobody, non, none, noone, nor, normally, not, nothing, novel, now, nowhere, obviously, of, off, often, oh, ok, okay, old, on, once, one, ones, only, onto, or, other, others, otherwise, ought, our, ours, ourselves, out, outside, over, overall, own, particular, particularly, per, perhaps, placed, please, plus, possible, presumably, probably, provides, que, quite, qv, rather, rd, re, really, reasonably, regarding, regardless, regards, relatively, respectively, right, said, same, saw, say, saying, says, second, secondly, see, seeing, seem, seemed, seeming, seems, seen, self, selves, sensible, sent, serious, seriously, seven, several, shall, she, should, shouldn’t, since, six, so, some, somebody, somehow, someone, something, sometime, sometimes, somewhat, somewhere, soon, sorry, specified, specify, specifying, still, sub, such, sup, sure, t’s, take, taken, tell, tends, th, than, thank, thanks, thanx, that, that’s, thats, the, their, theirs, them, themselves, then, thence, there, there’s, thereafter, thereby, therefore, therein, theres, thereupon, these, they, they’d, they’ll, they’re, they’ve, think, third, this, thorough, thoroughly, those, though, three, through, throughout, thru, thus, to, together, too, took, toward, towards, tried, tries, truly, try, trying, twice, two, un, under, unfortunately, unless, unlikely, until, unto, up, upon, us, use, used, useful, uses, using, usually, value, various, very, via, viz, vs, want, wants, was, wasn’t, way, we, we’d, we’ll, we’re, we’ve, welcome, well, went, were, weren’t, what, what’s, whatever, when, whence, whenever, where, where’s, whereafter, whereas, whereby, wherein, whereupon, wherever, whether, which, while, whither, who, who’s, whoever, whole, whom, whose, why, will, willing, wish, with, within, without, won't, wonder, would, would, wouldn't, yes, yet, you, you'd, you'll, you're, you've, your, yours, yourself, yourselves, zero\".replace('’',\"'\").split(', ')\n",
    "\n",
    "end_words = '|'.join(['\\,','\\.','\\?','\\!','\\-','\\:','\\;','\\r','\\n','\\t','\\(','\\)','\\{','\\}',\"\\'s\",\"\\_\",\"\\&\", \"\\#\", \"\\@\", \"\\#\",\"\\^\",\"\\*\",\"\\/\",\"\\[\",\"\\]\"])\n",
    "\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18706526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class Preprocessor:\n",
    "\n",
    "    \n",
    "    def __init__(self, stop_words, end_words, stemmer):\n",
    "        self.stop_words = stop_words\n",
    "        self.end_words = end_words\n",
    "        self.stemmer = stemmer\n",
    "        \n",
    "    def preprocess(self, raw_data):\n",
    "        tokenized_data = self.tokenize(raw_data)\n",
    "        stemmed_data = self.stemming(tokenized_data)\n",
    "        \n",
    "        return stemmed_data\n",
    "    \n",
    "    def tokenize(self, data):\n",
    "        # replace end words with space\n",
    "        end_replaced = re.sub(self.end_words, \" \", data.lower())\n",
    "        \n",
    "        # split\n",
    "        script_chunks = end_replaced.split(' ')\n",
    "        \n",
    "        # remove stop_wrods\n",
    "        filtered_script = filter(lambda x: len(x) > 1 and ((x in stop_words) is False), script_chunks)\n",
    "        \n",
    "        return [\"{}\".format(key.replace('\"', \"\").replace(\"'\",\"\")) for key in list(filtered_script)]\n",
    "    \n",
    "    def stemming(self, words):\n",
    "        return [self.stemmer.stem(word) for word in words]\n",
    "    \n",
    "    def check_keyword_frequency(self, raw_keywords):\n",
    "        keyword_dict = {key: 0 for key in list(set(raw_keywords))}\n",
    "        \n",
    "        for keyword in raw_keywords:\n",
    "            keyword_dict[keyword] += 1\n",
    "\n",
    "        return keyword_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd9cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Preprocessor(stop_words=stop_words, end_words=end_words, stemmer=PorterStemmer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f0a0b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def preprocess_genre(path, genre_name):\n",
    "    raw_file = open(f\"{path}/raw/{genre_name}.json\", \"r\")\n",
    "    raw_json = json.loads(raw_file.read())\n",
    "    raw_file.close()\n",
    "    \n",
    "    genre_dict = {}\n",
    "    for name, raw_script in raw_json:\n",
    "        tokenized_script = processor.tokenize(raw_script)\n",
    "        stemmed_script = processor.stemming(tokenized_script)\n",
    "        keyword_frequency = processor.check_keyword_frequency(stemmed_script)\n",
    "        \n",
    "        for keyword, count in keyword_frequency.items():\n",
    "            if keyword not in genre_dict:\n",
    "                genre_dict[keyword] = 0\n",
    "            genre_dict[keyword] += count\n",
    "    \n",
    "    genre_file = open(f\"{path}/preprocessed/{genre_name}.json\", \"w\")\n",
    "    json.dump(genre_dict, genre_file)\n",
    "    genre_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "376c4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Short', 'Thriller', 'War', 'Western']:\n",
    "    preprocess_genre('./data/grouped_by_genre/', genre)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2936cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Short', 'Thriller', 'War', 'Western'] \n",
    "import os\n",
    "def process_movie(path, genre_name):\n",
    "    raw_file = open(f\"{path}/raw/{genre_name}.json\", \"r\")\n",
    "    raw_json = json.loads(raw_file.read())\n",
    "    raw_file.close()\n",
    "    \n",
    "    folder_name = f'./data/grouped_by_movie/preprocessed'\n",
    "    \n",
    "    movie_dict = {}\n",
    "    for name, raw_script in raw_json:\n",
    "        tokenized_script = processor.tokenize(raw_script)\n",
    "        keyword_frequency = processor.check_keyword_frequency(tokenized_script)\n",
    "        \n",
    "        movie_dict[name] = keyword_frequency\n",
    "        \n",
    "    movie_file = open(f\"{folder_name}/{genre_name}.json\", \"w\")\n",
    "    json.dump(movie_dict, movie_file)\n",
    "    movie_file.close()\n",
    "\n",
    "\n",
    "def gen_movie_dict(path, raw_path):\n",
    "    for genre in genres:\n",
    "        movie_dict = {}\n",
    "        process_movie(raw_path, genre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dd5b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_movie_dict('./data/grouped_by_movie/', './data/grouped_by_genre/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc766194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1209\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f = open(\"./data/grouped_by_movie/movies.json\", \"r\")\n",
    "movies = json.loads(f.read())\n",
    "print(len(movies.keys()))\n",
    "a = set()\n",
    "for keywords in movies.values():\n",
    "    a.update(set(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa8202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146125\n"
     ]
    }
   ],
   "source": [
    "print(len(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
